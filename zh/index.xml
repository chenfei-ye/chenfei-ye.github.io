<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>主页</title>
    <link>https://chenfei-ye.github.io/zh/</link>
      <atom:link href="https://chenfei-ye.github.io/zh/index.xml" rel="self" type="application/rss+xml" />
    <description>主页</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh-Hans</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>https://chenfei-ye.github.io/media/icon_hu80a2544e7b046e76dea23103488b26f7_18404_512x512_fill_lanczos_center_3.png</url>
      <title>主页</title>
      <link>https://chenfei-ye.github.io/zh/</link>
    </image>
    
    <item>
      <title>Example Talk</title>
      <link>https://chenfei-ye.github.io/zh/talk/example-talk/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/talk/example-talk/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Wowchemy&amp;rsquo;s &lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>利用Surfplot和Brainspace进行脑图可视化</title>
      <link>https://chenfei-ye.github.io/zh/post/202402_surfplot_brainspace/</link>
      <pubDate>Sun, 18 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202402_surfplot_brainspace/</guid>
      <description>&lt;h3 id=&#34;可视化&#34;&gt;可视化：&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/danjgale/surfplot&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;surfplot&lt;/a&gt;提供了脑图可视化方法，基于&lt;a href=&#34;https://brainspace.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;brainspace&lt;/a&gt;开发实现。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/chenfei-ye/chenfei-ye.github.io/tree/main/zh/post/202402_surfplot_brainspace/Brain_Atlas_Plot.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;针对Yeo脑网络的可视化参考示例&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;依赖提示：建议运行环境预装&lt;a href=&#34;https://humanconnectome.org/software/workbench-command&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;wb_command&lt;/a&gt;并写入环境变量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何可视化NIFTI：&lt;a href=&#34;https://github.com/danjgale/surfplot&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;surfplot&lt;/a&gt;默认仅支持GIFTI或CIFTI的皮层染色。对于NIFTI文件，需要&lt;a href=&#34;https://netneurolab.github.io/neuromaps/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;neuromap&lt;/a&gt;实现空间转换，参考：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;已知坑1：远程服务器安装&lt;code&gt;surfplot&lt;/code&gt;后，如果&lt;code&gt;jupyter&lt;/code&gt;可视化出现内核挂掉的错误，大概率来源于&lt;code&gt;brainspace&lt;/code&gt;中&lt;code&gt;vtk&lt;/code&gt;的问题，须参考&lt;a href=&#34;https://github.com/MICA-MNI/BrainSpace/issues/66&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;官方解决方案&lt;/a&gt;重装&lt;code&gt;vtk&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;from neuromaps.datasets import fetch_fslr
from surfplot import Plot
from neuromaps import transforms

gii_lh, gii_rh= transforms.mni152_to_fslr(nifti_file_path_in_MNI152_space, &amp;#39;32k&amp;#39;)
surfaces = fetch_fslr()
lh, rh = surfaces[&amp;#39;inflated&amp;#39;]
p = Plot(lh, rh, layout =  &amp;#39;row&amp;#39;, size =  (1000, 400), zoom = 1.2)
p.add_layer({&amp;#39;left&amp;#39;: gii_lh, &amp;#39;right&amp;#39;: gii_rh}, cbar=True)
fig = p.build()
fig.show()
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;梯度分析&#34;&gt;梯度分析&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://brainspace.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;brainspace&lt;/a&gt;，一个Python/Matlab工具箱，用于(i)识别梯度，(ii)梯度对齐，(iii)梯度可视化。BrainSpace还可以对梯度与其他大脑特征之间的关联进行控制研究，生成空模型，以解释空间自相关性。验证实验证明了该工具在分析不同空间尺度上的功能和微观结构梯度时的实用性和一致性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;已知坑1：&lt;code&gt;brainspace&lt;/code&gt;对于大矩阵计算（如10K节点）的运算时间会很慢，建议按&lt;a href=&#34;https://github.com/MICA-MNI/BrainSpace/issues/85&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;此方案&lt;/a&gt;手动修正源代码从而提速。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>如何提取脑图谱/脑区label文件的中心坐标</title>
      <link>https://chenfei-ye.github.io/zh/post/202402_label_coord/</link>
      <pubDate>Sat, 17 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202402_label_coord/</guid>
      <description>&lt;h3 id=&#34;解决&#34;&gt;解决&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;import  nilearn.plotting  as  pl
import  nibabel  as  nib

labels_img  =  nib.load(&amp;#39;/data/cye_code/BIDS-fmripost/atlases/AAL1PD25_MNI.nii.gz&amp;#39;)
coords  =  pl.find_parcellation_cut_coords(labels_img)
np.savetxt(&amp;#34;/data/cye_code/BIDS-fmripost/atlases/coords.csv&amp;#34;, coords.astype(int), delimiter=&amp;#34;,&amp;#34;)
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>VSCode在debug时无法设置第三方包函数断点的问题</title>
      <link>https://chenfei-ye.github.io/zh/post/202402_vscode_debug/</link>
      <pubDate>Thu, 15 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202402_vscode_debug/</guid>
      <description>&lt;h3 id=&#34;解决&#34;&gt;解决&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# add a launch configuration 
&amp;#34;justMyCode&amp;#34;:false` 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;See &lt;a href=&#34;https://code.visualstudio.com/docs/python/debugging#_justmycode&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code.visualstudio.com/docs/python/debugging#_justmycode&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>VSCode连接服务器失败的问题</title>
      <link>https://chenfei-ye.github.io/zh/post/202402_vscode_upgrade/</link>
      <pubDate>Tue, 06 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202402_vscode_upgrade/</guid>
      <description>&lt;h3 id=&#34;问题&#34;&gt;问题：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;前几天连接服务器时一切正常&lt;/li&gt;
&lt;li&gt;今天连接服务器时突然显示The remote host may not meet VS Code Server&amp;rsquo;s prerequisites for glibc and libstdc++&lt;/li&gt;
&lt;li&gt;最后发现是VSCode更新版本后提高了对服务器版本的要求（新版的VSCode要求glibc&amp;gt;=2.28），而服务器端Ubuntu 18.04版本的glibc=2.27。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;解决&#34;&gt;解决&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;卸载本机VSCode，下载并安装1.85版的VSCode，并关闭VSCode自动更新，&lt;a href=&#34;https://zhuanlan.zhihu.com/p/553996841&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;参考&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;在VSCode插件商城中重装remote-ssh插件。&lt;/li&gt;
&lt;li&gt;大功告成。&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Penguin服务器使用说明</title>
      <link>https://chenfei-ye.github.io/zh/post/202401_penguin/</link>
      <pubDate>Sun, 03 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202401_penguin/</guid>
      <description>&lt;h3 id=&#34;服务器资源&#34;&gt;服务器资源：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;penguin&lt;/code&gt;: 计算服务器(81.xx.xx.124)：AMD EPYC™ Milan(2.55GHz/3.5GHz） (64 threads), 128GB RAM, 2TB HDD；256TB &lt;a href=&#34;https://cloud.tencent.com/product/cos&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;对象存储COS&lt;/a&gt;; Ubuntu 18.04 OS&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;使用说明&#34;&gt;使用说明&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;服务器购买自腾讯云，公网IP。&lt;/li&gt;
&lt;li&gt;此台服务器没有显卡，没有显卡，没有显卡。&lt;/li&gt;
&lt;li&gt;用户私有数据存放在&lt;code&gt;/workspace&lt;/code&gt;目录。例如对于用户&lt;code&gt;zyx&lt;/code&gt;，私有目录为&lt;code&gt;/workspace/zyx&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;大体量数据可存储在对象存储COS，路径在&lt;code&gt;/data/&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;超过10GB的大体量软件安装，勿私自操作，请联系为师帮助。&lt;/li&gt;
&lt;li&gt;请使用ssh方式连接服务器，本地客户端推荐使用&lt;a href=&#34;https://tabby.sh/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tabby&lt;/a&gt;和&lt;a href=&#34;https://winscp.net/eng/index.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;winscp&lt;/a&gt;工具。有使用GUI需求时可联系为师。&lt;/li&gt;
&lt;li&gt;查看系统CPU运行状态用命令&lt;code&gt;htop&lt;/code&gt;。并行计算时，线程数不要超过逻辑CPU核数（64 threads），同时警惕内存溢出。&lt;/li&gt;
&lt;li&gt;跑任务，或者基于vscode/jupyter debug，请使用&lt;code&gt;tmux&lt;/code&gt;管理会话。具体&lt;a href=&#34;https://zhuanlan.zhihu.com/p/98384704&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;参考这里&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;python编程请用户使用各自的conda虚拟环境进行管理，装包切勿都装在&lt;code&gt;base&lt;/code&gt;环境。具体&lt;a href=&#34;https://zhuanlan.zhihu.com/p/339662352&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;参考这里&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;对于pipeline编写和调试（尤其深度学习），建议在服务器docker容器内操作。参考&lt;a href=&#34;https://chenfei-ye.github.io/post/202206_jupyter_docker/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jupyter远程调试docker容器具体&lt;/a&gt; 及&lt;a href=&#34;https://chenfei-ye.github.io/post/202206_vscode_docker/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VScode远程调试docker容器&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;神经影像分析基础镜像&lt;code&gt;mindsgo-sz-docker.pkg.coding.net/neuroimage_analysis/base/msg_baseimage_cuda11:deepFS&lt;/code&gt;，内置&lt;code&gt;python3.8 + cuda11.0.221 + cudnn8.0.3 + pytorch1.7.0 + nibabel + scikit-learn + nilearn&lt;/code&gt;，同时集成了&lt;code&gt;ANTS&lt;/code&gt;，&lt;code&gt;FSL6.0.4&lt;/code&gt;，&lt;code&gt;MRtrix3.0.2&lt;/code&gt;，&lt;code&gt;c3d&lt;/code&gt;，&lt;code&gt;freesurfer7.3.2&lt;/code&gt;等常用软件。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 调用命令示例：
docker run -it --rm --name deepFS \
-v &amp;lt;localpath&amp;gt;:/dataio \
mindsgo-sz-docker.pkg.coding.net/neuroimage_analysis/base/msg_baseimage_cuda11:deepFS
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;penguin已开通用户&#34;&gt;penguin已开通用户：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;lyx&lt;/li&gt;
&lt;li&gt;zx&lt;/li&gt;
&lt;li&gt;rby&lt;/li&gt;
&lt;li&gt;lhh&lt;/li&gt;
&lt;li&gt;dy&lt;/li&gt;
&lt;li&gt;hyt&lt;/li&gt;
&lt;li&gt;rc&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;penguin已安装软件&#34;&gt;penguin已安装软件：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;tmux&lt;/li&gt;
&lt;li&gt;MRtrix3&lt;/li&gt;
&lt;li&gt;docker&lt;/li&gt;
&lt;li&gt;conda&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;penguin如何启用jupyter编程&#34;&gt;penguin如何启用jupyter编程：&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;创建自己的conda环境&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 以zyx为例
/opt/miniconda3/bin/conda init bash
### 根据提示，可能需要reopen一个新的终端生效配置，再执行后续命令
conda create -n zyx python=3.8 
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;激活zyx环境&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;conda activate zyx #若提示权限问题，可使用chmod命令来更改权限
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;将当前conda环境添加进jupyter kernel&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;pip install ipykernel -i https://pypi.tuna.tsinghua.edu.cn/simple 
python -m ipykernel install  --name zyx
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;以上实现了jupyter kernel的环境添加，只需要操作一次即可。后续每次编程只需要启动jupyter会话即可。&lt;/li&gt;
&lt;li&gt;验证获取服务器的jupyter可用端口：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;jupyter notebook --config /root/.jupyter/jupyter_notebook_config.py --allow-root
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;根据提示获知可用端口，如8888，然后ctrl+C退出。鉴于服务器是公网IP，需要使用端口转发，建议打开windows自带的powershell，新建端口转发的ssh通道。为保证会话进程在后台始终活跃，建议使用tmux进程管理jupyter后台：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 以下在windows powershell中执行，以zyx用户为例
# 8000是本地端口，8888是远程jupyter端口（根据上一步获取的实际可用端口做修改）
# remote_server_ip改成服务器真实IP

ssh -L  8000:localhost:8888 zyx@remote_server_ip

# 新建tmux会话，以zyx用户为例
tmux new -s jupyter_zyx
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;进入编程根目录（自行指定）&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;cd /data/zyx
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;启动jupyter会话&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;jupyter notebook --config /root/.jupyter/jupyter_notebook_config.py --allow-root
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;此时会生成IP，如：http://127.0.0.1:8888/tree?token=5d3dfa55f08fa4e4c2f4a7f217fe0f64c135c73f7bd4e6ea
把其中端口8888替换成本地端口即可（8000），本地浏览器键入IP实现访问。&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;如果访问不了，需要换新的本地端口重新尝试，如8001。如果可以正常访问，后续可以通过tmux会话管理jupyter后台，如重新切入到已有tmux 会话：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;tmux a -t jupyter_zyx
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;只要jupyter后台持续活跃，理论上就可以网页访问jupyter。&lt;/p&gt;
&lt;ol start=&#34;9&#34;&gt;
&lt;li&gt;新建conda环境（如zyx）对应的ipykernel，即可使用。
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;zyx.png&#34; srcset=&#34;
               /zh/post/202401_penguin/zyx_hu6b63f1b839867e7dd02aa443c6d0da2a_48918_38bc98183a5cb60c07efdc28dffe949b.webp 400w,
               /zh/post/202401_penguin/zyx_hu6b63f1b839867e7dd02aa443c6d0da2a_48918_c30ca99c08873dd847b7261d7b6f4aa7.webp 760w,
               /zh/post/202401_penguin/zyx_hu6b63f1b839867e7dd02aa443c6d0da2a_48918_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://chenfei-ye.github.io/zh/post/202401_penguin/zyx_hu6b63f1b839867e7dd02aa443c6d0da2a_48918_38bc98183a5cb60c07efdc28dffe949b.webp&#34;
               width=&#34;760&#34;
               height=&#34;229&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>电信本科毕设方向</title>
      <link>https://chenfei-ye.github.io/zh/post/202309_gradproj/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202309_gradproj/</guid>
      <description>&lt;h3 id=&#34;1-人脑影像功能动态分析计算方法&#34;&gt;1. 人脑影像功能动态分析计算方法&lt;/h3&gt;
&lt;p&gt;近二十年来，静息态(resting-state, RS)功能磁共振成像(fMRI)为自发大脑活动的时空组织带来了新的曙光。RS波动的丰富和复杂结构可以用不同的脑网络(resting-state networks, RSNs)来描述，这是由一组分布脑区的相干波动引起的。通常，在6分钟或更长时间的整个RS扫描中计算空间位置之间的统计相互依赖关系；Pearson相关系数是最常用的功能连接(functional connectivity, FC)指标。&lt;/p&gt;
&lt;p&gt;最近，FC被证明随着时间的推移而波动，这意味着在整个RS扫描上假设平稳性的测量可能过于简单，无法捕获RS活动的全部程度。自这些初步发现以来，随后的研究迅速蓬勃发展，以研究所谓的动态功能连接(dynamic FC, dFC)，试图以有意义的方式解析RS的dFC已经在一系列方法学变体中展开。除了作为各种脑部疾病生物标志物的潜力，dFC对神经疾病的直接治疗应用也可以预见。在此背景下，通过dFC方法追踪大脑功能动力学作为一种有吸引力的工具脱颖而出。此外，调节活动或连接的动态特征也可能被证明是治疗大脑动力学受到特别阻碍的疾病的有效策略。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本研究方向偏磁共振影像计算，将聚焦于人脑静息态功能磁共振影像的动态分析算法研究。目前组内已有1名博士生在研。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;参考文献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Preti MG, Bolton TA, Van De Ville D. The dynamic functional connectome: State-of-the-art and perspectives. Neuroimage. 2017 Oct 15;160:41-54. doi: 10.1016/j.neuroimage.2016.12.061. Epub 2016 Dec 26. PMID: 28034766.&lt;/li&gt;
&lt;li&gt;Long Y, Cao H, Yan C, et al. Altered resting-state dynamic functional brain networks in major depressive disorder: Findings from the REST-meta-MDD consortium. Neuroimage Clin. 2020;26:102163. doi: 10.1016/j.nicl.2020.102163. Epub 2020 Jan 7. PMID: 31953148; PMCID: PMC7229351.&lt;/li&gt;
&lt;li&gt;Spencer APC, Goodfellow M. Using deep clustering to improve fMRI dynamic functional connectivity analysis. Neuroimage. 2022 Aug 15;257:119288. doi: 10.1016/j.neuroimage.2022.119288. Epub 2022 May 10. PMID: 35551991.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-脑影像神经集群建模及脑疾病应用&#34;&gt;2. 脑影像神经集群建模及脑疾病应用&lt;/h3&gt;
&lt;p&gt;使用非线性动态系统理论模型对大尺度大脑活动进行建模，可以将来自多种模式的实验数据整合到一个通用框架中，从而促进对神经认知功能和病变的预测。有证据表明，神经元集群的非线性动态是适应性皮层活动的核心。同样，异常的动态过程似乎是许多大脑疾病的基础。&lt;/p&gt;
&lt;p&gt;神经集群建模（Neural Mass Model, NMM） 描述了一个局部群体的相互作用的神经元，如锥体和抑制细胞。但局域群体和支持大脑功能的大尺度系统之间仍然存在几个数量级。通过将一系列NMM耦合到介观和宏观环路，可以搭建起大尺度的脑动力学模型。 每个神经元群体节点(即每个 NMM)内的动态因此反映了局部群体活动加上来自远端区域(其他节点)和随机波动的影响。这种大尺度的脑网络模型是一个多尺度的系综的系综，在不同的尺度上有不同的组织规则。&lt;/p&gt;
&lt;p&gt;将NMM耦合成更大的系统需要依靠解剖连接，即连接组。对于人脑，磁共振DTI成像可以提供解剖连接，磁共振fMRI成像可以表征脑功能活动。由此得到的全脑动力学模型在网络节点间的传导时延、混沌或随机动力学的模式仍有待厘清。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本研究方向偏动力学分析计算（模拟仿真），将聚焦于基于人脑复杂网络NMM的神经动力学特征及其在神经系统疾病上的机制探索和临床应用。目前组内已有1名硕士生在研。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;参考文献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Breakspear M. Dynamic models of large-scale brain activity. Nat Neurosci. 2017 Feb 23;20(3):340-352. doi: 10.1038/nn.4497. PMID: 28230845.&lt;/li&gt;
&lt;li&gt;El Houssaini K, Bernard C, Jirsa VK. The Epileptor Model: A Systematic Mathematical Analysis Linked to the Dynamics of Seizures, Refractory Status Epilepticus, and Depolarization Block. eNeuro. 2020 Mar 24;7(2):ENEURO.0485-18.2019. doi: 10.1523/ENEURO.0485-18.2019. PMID: 32066612; PMCID: PMC7096539.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-人脑多模态影像的低维嵌入表征方法&#34;&gt;3. 人脑多模态影像的低维嵌入表征方法&lt;/h3&gt;
&lt;p&gt;如何利用多模态神经影像数据解析人脑极其复杂的功能机制、形成明确疾病早期标志物成为了推动脑医学前沿的重大难题。造成这种困局的主要原因包括： (1)脑磁共振影像数据具有高维异构的特点，计算复杂性高，影像特征提取困难；(2)脑磁共振影像模态融合难。已有的绝大部分研究往往只使用了单模态脑影像（对应MRI单序列扫描数据），难以将散乱在影像中的人脑信息集成一个能描述神经异常病变的全景图，而近年来出现模态融合方法大多仍停留在特征融合层面，无法有效捕捉模态间完整的互补信息；(3)疾病分类模型普遍泛化性低。已有的影像分析算法未能有效地将众多的多中心小样本脑影像数据整合成一个有效的大数据集进行分析，未能突破脑影像小样本造成的学习算法低泛化能力的问题，仍然需要新的计算方法才能逐步推向临床应用。&lt;/p&gt;
&lt;p&gt;简单汇聚单模态特征应用整个多模态特征集构建是低效的，所以如何捕捉各模态之间进行深度交互以丰富疾病表征尤为重要。近年来，结合深度学习技术和多模态磁共振影像技术研究构建脑疾病自动分类模型也逐渐兴起。深度学习区别于机器学习，更擅长于编码高度非线性特征，并且基于数据驱动的特点，使得模型的特征不仅仅局限于手动提取或者非线性分析方法提取的特征，更是可以通过多层非线性表达编码更为抽象的表征。其中的代表性工作是BrainGNN：提出了基于ROI启发的图卷积层和池化层，通过任务对于ROI的启发和敏感性来实现对脑区特征的特异性编码，并且基于该方法可以有效找到与疾病相关的生物标志物，具有群体分析和个体分析的重要特性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本研究方向偏人工智能算法，将聚焦于基于人脑网络的图神经网络（GNN）学习，实现脑影像低维嵌入表征。目前组内已有2名博士生在研。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;参考文献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Schneider S, Lee JH, Mathis MW. Learnable latent embeddings for joint behavioural and neural analysis. Nature. 2023 May;617(7960):360-368. doi: 10.1038/s41586-023-06031-6. Epub 2023 May 3. PMID: 37138088; PMCID: PMC10172131.&lt;/li&gt;
&lt;li&gt;Kim JH, Zhang Y, Han K, Wen Z, Choi M, Liu Z. Representation learning of resting state fMRI with variational autoencoder. Neuroimage. 2021 Nov 1;241:118423. doi: 10.1016/j.neuroimage.2021.118423. Epub 2021 Jul 23. PMID: 34303794; PMCID: PMC8485214.&lt;/li&gt;
&lt;li&gt;Yang Y, Ye C, Guo X, Wu T, Xiang Y, Ma T. Mapping Multi-modal Brain Connectome for Brain Disorder Diagnosis via Cross-modal Mutual Learning. IEEE Trans Med Imaging. 2023 Jul 13;PP. doi: 10.1109/TMI.2023.3294967. Epub ahead of print. PMID: 37440391.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-神经调控下的脑影像标志物挖掘&#34;&gt;4. 神经调控下的脑影像标志物挖掘&lt;/h3&gt;
&lt;p&gt;深脑电刺激（deep brain stimulation, DBS）是帕金森病等多种神经退行疾病的主要干预手段，自上世纪80 年代开始应用于临床，2002年获得美国FDA批准，30多年来全球有超过30万人接受了该疗法。然而其临床疗效的普适性不强、刺激参数优化方式低效、长期慢性刺激容易产生不良作用。临床困境的背后是DBS作用机制不清。目前的主流观点认为DBS 不仅在局部刺激靶区发挥作用，而且在全脑范围内通过涉及运动控制的功能连接脑区产生广泛分布的脑网络效应。然而其具体机制仍未阐明，严重限制了DBS手术方案的精准优化。因此，如何研究模拟帕金森病（PD）患者人脑连接组的功能损伤和刺激响应，是DBS干预方案个体调控精准化的重要发展趋势，也成为了功能神经外科的迫切临床需求。DBS在功能失调的神经回路中放置一个电极来提供电刺激，以抑制异常的活动和驱动一个不活跃的网络。尽管DBS优势明显，但它的治疗作用机制仍不完全清楚。&lt;/p&gt;
&lt;p&gt;神经影像学研究，旨在将行为的变异与大脑的变化联系起来。磁共振成像（MRI）自上世纪90年代初被发现以来，已成为实现这一目标最有效的方法之一。作为一种探测全脑活动的非侵入性工具，功能磁共振成像fMRI能够研究复杂的人脑活动过程及其在不同时空域的功能整合和分离，因此基于fMRI影像的人脑连接组自动重建、分析与功能信息解码研究十分关键。如何在DBS外部刺激过程中对人脑fMRI信号进行有效处理并挖掘疾病标志物，对患者大脑的功能障碍解码与症状康复预测具有重要意义。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本研究方向偏磁共振影像计算，将聚焦于DBS作用机制相关的多模态MRI影像标志物挖掘方法研究。目前组内已有1名博士生在研。本项目与上海交通大学瑞金医院团队合作开展&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;参考文献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chu C, He N, Zeljic K, Zhang Z, Wang J, Li J, Liu Y, Zhang Y, Sun B, Li D, Yan F, Zhang C, Liu C. Subthalamic and pallidal stimulation in Parkinson&amp;rsquo;s disease induce distinct brain topological reconstruction. Neuroimage. 2022 Jul 15;255:119196. doi: 10.1016/j.neuroimage.2022.119196. Epub 2022 Apr 9. PMID: 35413446.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cn-healthcare.com/articlewm/20221210/content-1481552.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.cn-healthcare.com/articlewm/20221210/content-1481552.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Zhao S, Li G, Tong C, Chen W, Wang P, Dai J, Fu X, Xu Z, Liu X, Lu L, Liang Z, Duan X. Full activation pattern mapping by simultaneous deep brain stimulation and fMRI with graphene fiber electrodes. Nat Commun. 2020 Apr 14;11(1):1788. doi: 10.1038/s41467-020-15570-9. PMID: 32286290; PMCID: PMC7156737.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-神经调控下的脑影像状态切换机制&#34;&gt;5. 神经调控下的脑影像状态切换机制&lt;/h3&gt;
&lt;p&gt;（接研究方向4）DBS下的PD患者脑活动解码仍存在诸多问题亟待解决：首先，由于人脑复杂活动本身具有的高度动态特性，传统静息态fMRI测量无法捕获PD病理神经环路的全局功能活动，其解释价值十分有限，忽略了许多重要的脑状态变化信息；其次，临床PD患者往往具有多种症状且随时间波动，优化 DBS 参数配置的复杂性高，需要花费较长时间，即使患者频繁往返医院，以试错的方式不断调整，也可能无法达到最佳治疗效果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本研究方向偏脑网络计算，将聚焦于DBS作用下人脑的功能状态估计方法研究，阐明脑状态切换与临床症状改善的关系。目前组内已有1名博士生在研。本项目与上海交通大学瑞金医院团队合作开展&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;参考文献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chu C, Liu S, He N, Zeng Z, Wang J, Zhang Z, Zeljic K, van der Stelt O, Sun B, Yan F, Liu C, Li D, Zhang C. Subthalamic stimulation modulates motor network in Parkinson&amp;rsquo;s disease: recover, relieve and remodel. Brain. 2023 Jul 3;146(7):2780-2791. doi: 10.1093/brain/awad004. PMID: 36623929.&lt;/li&gt;
&lt;li&gt;McCormick DA, Nestvogel DB, He BJ. Neuromodulation of Brain State and Behavior. Annu Rev Neurosci. 2020 Jul 8;43:391-415. doi: 10.1146/annurev-neuro-100219-105424. Epub 2020 Apr 6. PMID: 32250724.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-神经外科手术导航系统智能模组设计&#34;&gt;6. 神经外科手术导航系统智能模组设计&lt;/h3&gt;
&lt;p&gt;传统的开颅手术方式是先根据核磁共振、CT等影像学资料，判断病灶的确切部位，以此制定手术方案。其局限性和盲目性显而易见，尤其是涉及大脑深部、病变组织体积小、与正常脑组织外观结构相似时，究竟切多大切多深，大多依赖于医生的个人经验。&lt;/p&gt;
&lt;p&gt;大脑是中枢神经系统的最高级部分，也是脑的主要部分，被誉为人体的“司令部”。但就是如此精密的器官仅比豆腐脑略硬一点，作为传导信号的脑神经元也是极为脆弱，缺血缺氧5分钟就会致使残疾甚至死亡。所以神经外科手术被人称作“在万丈深渊上走钢丝”，而手术导航系统的出世，实时显示患者脑部结构显示图，成为病人生命路上的的“灯塔”。如果有一幅“实时显现”的脑部结构显示图，这一问题就迎刃而解了。&lt;/p&gt;
&lt;p&gt;神经外科手术导航流程主要为手术计划、患者注册和导航定位三个步骤。
● 手术计划是医生通过手术计划软件，对患者的医学影像进行融合分析，制定出最佳的手术方案；
● 患者注册是医生在软件系统中，建立患者颅脑轮廓模型，踩击脚踏装置，就能开启全自动扫描注册过程；
● 导航定位是指医生根据不同手术的需求，为机器人替换合适的定位工具，通过配合使用专用的手术配件和软件模块，医生可以完成多种神经外科微创手术。&lt;/p&gt;
&lt;p&gt;在神经外科手术导航系统的基础上，神经外科手术机器人有效地把计算机辅助的空间定位算法技术、医学影像的融合技术、机器人的技术以及临床一线医生的实际临床经验有效地结合在一起，结合我们一些新的技术，可以使先前只能通过开颅来做手术的患者，变成微创手术。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本研究方向偏系统设计，将聚焦于神经外科手术导航关键技术研发与手术机器人系统集成，初步实现神外微创手术的自动化与智能化。本项目与哈工大深圳CPS中心王勃然老师团队合作开展&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;参考文献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mezger U, Jendrewski C, Bartels M. Navigation in surgery. Langenbecks Arch Surg. 2013 Apr;398(4):501-14. doi: 10.1007/s00423-013-1059-4. Epub 2013 Feb 22. PMID: 23430289; PMCID: PMC3627858.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cn-healthcare.com/articlewm/20200731/content-1134463.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.cn-healthcare.com/articlewm/20200731/content-1134463.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;7-人脑认知加工功能的影像梯度模式识别&#34;&gt;7. 人脑认知加工功能的影像梯度模式识别&lt;/h3&gt;
&lt;p&gt;皮层在结构上特定的空间排列模式锚定了人脑功能的分化表达。利用非线性流行学习等方法进行网络嵌入（network embedding），能够刻画个体脑网络梯度，从而在低维空间对脑网络的空间组织进行表达。最近研究发现，人脑中存在一个感觉运动脑区到跨模态脑区之间的核心梯度，一个脑区在这个核心梯度组织形式中的位置可以直接反映这个脑区的微观结构、遗传特征、连接和功能作用。对于神经变性病，有研究发现健康老年人群中，淀粉样蛋白更多的沉积在人脑连接梯度的跨模态部分，并且在梯度视角下该代谢标志物能够预测衰老过程中的短时记忆功能水平。因此探索脑网络梯度分布在神经变性作用下的趋同和变异，将有助于揭开衰老相关的神经变性过程中运动和认知功能损伤和重塑的原则。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本研究方向偏脑网络计算，将聚焦于人脑功能网络的梯度模式识别及疾病临床应用。目前组内已有1名博士生在研。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;参考文献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Vos de Wael R, Benkarim O, Paquola C, Lariviere S, Royer J, Tavakol S, Xu T, Hong SJ, Langs G, Valk S, Misic B, Milham M, Margulies D, Smallwood J, Bernhardt BC. BrainSpace: a toolbox for the analysis of macroscale gradients in neuroimaging and connectomics datasets. Commun Biol. 2020 Mar 5;3(1):103. doi: 10.1038/s42003-020-0794-7. PMID: 32139786; PMCID: PMC7058611.&lt;/li&gt;
&lt;li&gt;Ruan X, Huang X, Li Y, Kuang Z, Li M, Wei X. Dysfunction of human brain network hierarchy in Parkinson&amp;rsquo;s disease patients with freezing of gait. Parkinsonism Relat Disord. 2023 Jul;112:105446. doi: 10.1016/j.parkreldis.2023.105446. Epub 2023 May 24. PMID: 37245278.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;8-基于影像的脑连接组通信路由协议&#34;&gt;8. 基于影像的脑连接组通信路由协议&lt;/h3&gt;
&lt;p&gt;理解神经系统中的通信和信息处理是神经科学的核心目标。神经元素之间的信号传递和信息传输渗透到大脑功能的每一个方面和空间尺度：从神经元到神经元的突触传输，到神经元群体之间的交互，到整个大脑的区域共激活模式。理解控制神经信号灵活调节的机制是现代神经科学的持久挑战之一。为了解决这个问题，研究方向多种多样，包括但不限于神经编码，神经振荡的同步性和相干性，区域间通信子空间，以及神经动力学的计算模型。因此，通信这个主题既广泛又是神经科学探究的核心。在过去的二十年中，连通组学和网络神经科学的进步为研究复杂脑网络中的多突触通信开辟了新的途径。最近的工作对主流假设提出了质疑，即连通组信号仅通过最短路径进行，这导致了一系列替代网络通信模型的涌现。&lt;/p&gt;
&lt;p&gt;结构性大脑网络（连接组图） 根据一系列复杂的拓扑属性进行组织，包括一个由密集连接的中心节点，模块化和分层结构，以及小世界架构。这些大脑组织的原则在各种物种和空间尺度上都普遍存在，被推测是由于神经通信效率的进化压力产生的。区域间信号传递被认为能使远离的区域协调他们的活动，以应对不断变化的认知和行为需求，而神经通信的损伤可能涉及到多种神经精神疾病的病因和症状表现。因此，阐明控制连接组图通信的机制对于基础、认知和临床大脑科学的进步至关重要。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本研究方向偏脑网络计算（模拟仿真），属于图信号处理与通信路由的交叉方向，将聚焦于脑连接组通信路由协议的方法研究。本项目与哈工大深圳电信学院李伊川老师团队合作开展&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;参考文献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Seguin C, Sporns O, Zalesky A. Brain network communication: concepts, models and applications. Nat Rev Neurosci. 2023 Sep;24(9):557-574. doi: 10.1038/s41583-023-00718-5. Epub 2023 Jul 12. PMID: 37438433.&lt;/li&gt;
&lt;li&gt;Graham D, Avena-Koenigsberger A, Mišić B. Editorial: Network Communication in the Brain. Netw Neurosci. 2020 Nov 1;4(4):976-979. doi: 10.1162/netn_e_00167. PMID: 33195944; PMCID: PMC7655038.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>BrainNet实验室服务器使用说明</title>
      <link>https://chenfei-ye.github.io/zh/post/202309_cyelab/</link>
      <pubDate>Fri, 22 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202309_cyelab/</guid>
      <description>&lt;h3 id=&#34;目前有两台服务器资源&#34;&gt;目前有两台服务器资源：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;spider&lt;/code&gt;: 计算服务器(10.2xx.xx.140)：AMD EPYC 7642 48-Core Processor (96 threads), RTX4070 ×2, 128GB RAM, 8TB HDD；Ubuntu 18.04 OS&lt;/li&gt;
&lt;li&gt;&lt;code&gt;zebra&lt;/code&gt;:  存储服务器(10.2xx.xx.127)：Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz (28 threads), 64GB RAM, 250GB SSD + 87TB HDD；Ubuntu 22.04 OS&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;使用说明&#34;&gt;使用说明&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;服务器均是校园网IP，校外使用请登录学校VPN。&lt;/li&gt;
&lt;li&gt;跑分析计算目前只能用&lt;code&gt;spider&lt;/code&gt;，&lt;code&gt;zebra&lt;/code&gt;只用于存放公用数据。&lt;code&gt;zebra&lt;/code&gt;的存储空间已映射到&lt;code&gt;spider&lt;/code&gt;的本地路径&lt;code&gt;/zebra&lt;/code&gt;，可基于该路径实现两台服务器之间的数据同步。&lt;/li&gt;
&lt;li&gt;对于计算服务器，私有数据存放在&lt;code&gt;/data/&lt;/code&gt;目录。例如对于用户&lt;code&gt;cyc&lt;/code&gt;，私有目录为&lt;code&gt;/data/cyc&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;大体量数据切勿存放在&lt;code&gt;/home&lt;/code&gt;路径，因为根目录空间有限（对应SSD系统盘）。&lt;/li&gt;
&lt;li&gt;超过10GB的大体量软件安装，勿私自操作，请联系为师帮助。&lt;/li&gt;
&lt;li&gt;请使用ssh方式连接服务器，本地客户端推荐使用&lt;a href=&#34;https://tabby.sh/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tabby&lt;/a&gt;和&lt;a href=&#34;https://winscp.net/eng/index.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;winscp&lt;/a&gt;工具。有使用GUI需求时可联系为师。&lt;/li&gt;
&lt;li&gt;查看系统CPU运行状态用命令&lt;code&gt;htop&lt;/code&gt;。并行计算时，线程数不要超过逻辑CPU核数（96 threads for &lt;code&gt;spider&lt;/code&gt;），同时警惕内存溢出。查看显卡运行状态用命令&lt;code&gt;nvidia-smi -l 2&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;跑任务，或者基于vscode/jupyter debug，请使用&lt;code&gt;tmux&lt;/code&gt;管理会话。具体&lt;a href=&#34;https://zhuanlan.zhihu.com/p/98384704&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;参考这里&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;python编程请用户使用各自的conda虚拟环境进行管理，装包切勿都装在&lt;code&gt;base&lt;/code&gt;环境。具体&lt;a href=&#34;https://zhuanlan.zhihu.com/p/339662352&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;参考这里&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;对于pipeline编写和调试（尤其深度学习），建议在服务器docker容器内操作。参考&lt;a href=&#34;https://chenfei-ye.github.io/post/202206_jupyter_docker/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jupyter远程调试docker容器具体&lt;/a&gt; 及&lt;a href=&#34;https://chenfei-ye.github.io/post/202206_vscode_docker/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VScode远程调试docker容器&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;spider&lt;/code&gt;目前只安装了显卡驱动，没有装cuda和cudnn。基于GPU的深度学习算法研究推荐用docker容器，可以根据需求拉取&lt;a href=&#34;https://hub.docker.com/r/pytorch/pytorch/tags&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pytorch官方镜像&lt;/a&gt;，或者使用为师倾力打造的神经影像分析基础镜像&lt;code&gt;mindsgo-sz-docker.pkg.coding.net/neuroimage_analysis/base/msg_baseimage_cuda11:deepFS&lt;/code&gt;，内置&lt;code&gt;python3.8 + cuda11.0.221 + cudnn8.0.3 + pytorch1.7.0 + nibabel + scikit-learn + nilearn&lt;/code&gt;，同时集成了&lt;code&gt;ANTS&lt;/code&gt;，&lt;code&gt;FSL6.0.4&lt;/code&gt;，&lt;code&gt;MRtrix3.0.2&lt;/code&gt;，&lt;code&gt;c3d&lt;/code&gt;，&lt;code&gt;freesurfer7.3.2&lt;/code&gt;等常用软件。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 调用命令示例：
docker run -it --rm --gpus all --name deepFS \
-v &amp;lt;localpath&amp;gt;:/dataio \
mindsgo-sz-docker.pkg.coding.net/neuroimage_analysis/base/msg_baseimage_cuda11:deepFS
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;spider已开通用户&#34;&gt;spider已开通用户：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;zyx&lt;/li&gt;
&lt;li&gt;cyc&lt;/li&gt;
&lt;li&gt;dzy&lt;/li&gt;
&lt;li&gt;csy&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spider已安装软件&#34;&gt;spider已安装软件：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;tmux&lt;/li&gt;
&lt;li&gt;MRtrix3&lt;/li&gt;
&lt;li&gt;docker&lt;/li&gt;
&lt;li&gt;conda&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spider如何启用jupyter编程&#34;&gt;spider如何启用jupyter编程：&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;创建自己的conda环境&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 以zyx为例
conda create -n zyx python=3.8
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;激活zyx环境&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;conda activate zyx
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;将当前conda环境添加进jupyter kernel&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;pip install ipykernel
python -m ipykernel install  --name zyx
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;以上实现了jupyter kernel的环境添加，只需要操作一次即可。后续每次编程只需要启动jupyter会话即可。为保证会话进程在后台始终活跃，建议新建tmux进程便于会话管理：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;tmux new -s jupyter_zyx
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;进入编程目录（自行指定）&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;cd /data/zyx
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;启动jupyter会话&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;jupyter notebook --config /root/.jupyter/jupyter_notebook_config.py --allow-root
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;此时会生成IP，如：http://spider:8890/
把其中&lt;code&gt;spider&lt;/code&gt;替换成实际IP即可（10.2xx.xx.140），本地浏览器键入IP实现访问（密码是&lt;code&gt;spider123&lt;/code&gt;）&lt;/p&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;新建conda环境（如zyx）对应的ipykernel，即可使用。
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;zyx.png&#34; srcset=&#34;
               /zh/post/202309_cyelab/zyx_hu6b63f1b839867e7dd02aa443c6d0da2a_48918_38bc98183a5cb60c07efdc28dffe949b.webp 400w,
               /zh/post/202309_cyelab/zyx_hu6b63f1b839867e7dd02aa443c6d0da2a_48918_c30ca99c08873dd847b7261d7b6f4aa7.webp 760w,
               /zh/post/202309_cyelab/zyx_hu6b63f1b839867e7dd02aa443c6d0da2a_48918_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://chenfei-ye.github.io/zh/post/202309_cyelab/zyx_hu6b63f1b839867e7dd02aa443c6d0da2a_48918_38bc98183a5cb60c07efdc28dffe949b.webp&#34;
               width=&#34;760&#34;
               height=&#34;229&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>rs-fMRI预处理完整流程</title>
      <link>https://chenfei-ye.github.io/zh/post/202308_fmripost/</link>
      <pubDate>Thu, 31 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202308_fmripost/</guid>
      <description>&lt;h1 id=&#34;bids-fmripost&#34;&gt;BIDS-fMRIpost&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;BIDS-fmripost&lt;/code&gt;是基于&lt;a href=&#34;https://fmriprep.org/en/stable/installation.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fMRIPrep&lt;/a&gt;  的后处理分析流程，基于&lt;a href=&#34;https://nilearn.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nilearn&lt;/a&gt;开发。分析功能包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;协变量回归（confound regression）&lt;/li&gt;
&lt;li&gt;空间平滑（spatial smoothing）&lt;/li&gt;
&lt;li&gt;基于脑区的BOLD信号提取 (BOLD signal extraction)&lt;/li&gt;
&lt;li&gt;功能连接网络计算 （FC network）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目前主要用于静息态功能磁共振影像数据的脑网络分析。该脚本的输入数据需符合&lt;a href=&#34;https://bids.neuroimaging.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BIDS格式&lt;/a&gt;，输入模态需包括3D-T1w和fMRI。目前支持的图谱包括：  &lt;code&gt;AAL1_MNI&lt;/code&gt;,  &lt;code&gt;AAL2_MNI&lt;/code&gt;,  &lt;code&gt;AAL3_MNI&lt;/code&gt;,  &lt;code&gt;desikan_T1w&lt;/code&gt;,  &lt;code&gt;destrieux_T1w&lt;/code&gt;,  &lt;code&gt;hcpmmp_T1w&lt;/code&gt;  ,  &lt;code&gt;schaefer100_MNI&lt;/code&gt;,  &lt;code&gt;schaefer200_MNI&lt;/code&gt;  ,  &lt;code&gt;schaefer400_MNI&lt;/code&gt;,  &lt;code&gt;schaefer1000_MNI&lt;/code&gt;,  &lt;code&gt;PD25_MNI&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;具体使用说明&lt;a href=&#34;https://github.com/chenfei-ye/BIDS-fMRIpost/blob/main/resources/README_Chs.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;点此&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>vtk文件转mesh格式</title>
      <link>https://chenfei-ye.github.io/zh/post/202308_vtk2mesh/</link>
      <pubDate>Thu, 31 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202308_vtk2mesh/</guid>
      <description>&lt;h1 id=&#34;vtk文件转mesh格式&#34;&gt;vtk文件转mesh格式&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;安装gmsh的binary文件 &lt;a href=&#34;https://gmsh.info/bin/Linux/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://gmsh.info/bin/Linux/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;转档&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 方式1 
gmsh -3 -o .msh 
# 方式2 
gmsh -3 -save
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;本地安装gmsh GUI软件打开验证&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其实也可以用&lt;code&gt;gmsh GUI&lt;/code&gt;直接转档&lt;/p&gt;
&lt;h3 id=&#34;注意容器系统环境可能需要安装libxcursor1才能支持gmsh&#34;&gt;注意：容器系统环境可能需要安装libxcursor1才能支持gmsh&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;apt install libxcursor1
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Spatial-temporal patterns of brain disconnectome in Alzheimers disease</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2023_j_disconnectome/</link>
      <pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2023_j_disconnectome/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A deep connectome learning network using graph convolution for connectome-disease association study</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2023_j_nn/</link>
      <pubDate>Sat, 22 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2023_j_nn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>关于最近一些MRI-T1w结构像处理pipeline的测试</title>
      <link>https://chenfei-ye.github.io/zh/post/202303_parcellate/</link>
      <pubDate>Sun, 12 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202303_parcellate/</guid>
      <description>&lt;h2 id=&#34;fastsurfer---全脑分割&#34;&gt;FastSurfer -&amp;gt; 全脑分割&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://deep-mi.org/research/fastsurfer/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://deep-mi.org/research/fastsurfer/&lt;/a&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://deep-mi.org/static/img/research/fastsurfer/01_teaser_white.png&#34; alt=&#34;!&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

FastSurfer is a fast and &lt;a href=&#34;https://deep-mi.org/research/fastsurfer/#proof-of-concept&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;extensively validated&lt;/a&gt; deep-learning pipeline for the fully automated processing of structural human brain MRIs. As such, it provides FreeSurfer conform outputs, enables scalable big-data analysis and time-critical clinical applications such as structure localization during image acquisition or extraction of quantitative measures.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 完整分割（GPU） 
docker run --gpus all -v /data/mg_data/mnt/bl_test/input:/data -v /data/mg_data/mnt/bl_test/fastsf_output:/output -v /data/freesurfer:/fs_license --rm deepmi/fastsurfer:gpu-v1.1.1 --fs_license /fs_license/freesurfer_license.txt --t1 /data/t1.nii --sid subject2 --sd /output --parallel 

# DKT Lookup table 
31和63作为脉络丛会被分割出来，应该当做LV，对应4和43 
77作为WMH，没有区分左右，不便合并
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;synthseg---全脑分割计算icv&#34;&gt;SynthSeg -&amp;gt; 全脑分割，计算ICV&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/BBillot/SynthSeg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/BBillot/SynthSeg&lt;/a&gt;
&lt;a href=&#34;https://surfer.nmr.mgh.harvard.edu/fswiki/SynthSeg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://surfer.nmr.mgh.harvard.edu/fswiki/SynthSeg&lt;/a&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://surfer.nmr.mgh.harvard.edu/fswiki/SynthSeg?action=AttachFile&amp;amp;do=get&amp;amp;target=robust2.png&#34; alt=&#34;!&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;code&gt;SynthSeg&lt;/code&gt; 可不依赖GPU，实测CPU多线程计算约2分钟内完成&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 分割 （完整） 
mri_synthseg --i /dataio/t1.nii --parc --robust --vol /dataio/vol.csv --qc /dataio/qc.csv --threads 172 --o /dataio/t1_seg.nii.gz 
# 注意 --resample如果输入本身是1mm iso，则不会生成resample图像
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;synthstrip---剥头皮&#34;&gt;SynthStrip -&amp;gt; 剥头皮&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://surfer.nmr.mgh.harvard.edu/docs/synthstrip/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://surfer.nmr.mgh.harvard.edu/docs/synthstrip/&lt;/a&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://surfer.nmr.mgh.harvard.edu/docs/synthstrip/resources/SynthStripExamples.png&#34; alt=&#34;!&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

SynthStrip is a skull-stripping tool that extracts brain signal from a landscape of image types, ranging across imaging modality, contrast, resolution, and subject population. It leverages a deep learning strategy that synthesizes arbitrary training images from segmentation maps to optimize a robust model agnostic to acquisition specifics.
&lt;a href=&#34;https://doi.org/10.1016/j.neuroimage.2022.119474&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.neuroimage.2022.119474&lt;/a&gt;&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 自动去头皮（多模态泛化性优秀），1分钟以内 
mri_synthstrip -i /dataio/t1.nii -o /dataio/t1_bet.nii -m /dataio/t1_mask.nii
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;sbtiv--计算icv&#34;&gt;sbTIV-&amp;gt; 计算ICV&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://freesurfer.net/fswiki/Samseg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://freesurfer.net/fswiki/Samseg&lt;/a&gt;
&lt;a href=&#34;https://freesurfer.net/fswiki/sbTIV&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://freesurfer.net/fswiki/sbTIV&lt;/a&gt;
Total intracranial volume (TIV/ICV) is an important covariate for volumetric analyses of the brain and brain regions. It is commonly used to correct for head size variation (i.e., &amp;rsquo;normalize&amp;rsquo; hippocampal volume size). The gold-standard method is manual delineation of T2 scans. Freesurfer currently provides the eTIV measure, described &lt;a href=&#34;https://freesurfer.net/fswiki/eTIV&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. It has been shown to be a robust covariate.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://freesurfer.net/fswiki/Samseg?action=AttachFile&amp;amp;do=get&amp;amp;target=3D_small.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;## 计算sbTIV (segmentation-based TIV)，大约5-10分钟
run_samseg --input /home/username/data/t1.nii --output /home/username/data/samsegOutput/ --threads 8
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;关于freesurfer图谱&#34;&gt;关于FreeSurfer图谱&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;DK图谱lookuptable &lt;a href=&#34;https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT&lt;/a&gt; &lt;a href=&#34;https://www.cis.jhu.edu/~parky/MRN/Desikan%20Region%20Labels%20and%20Descriptions.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.cis.jhu.edu/~parky/MRN/Desikan%20Region%20Labels%20and%20Descriptions.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DKT 图谱： &lt;a href=&#34;https://mindboggle.readthedocs.io/en/latest/labels.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://mindboggle.readthedocs.io/en/latest/labels.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HCPMMP图谱 ： &lt;a href=&#34;https://neuroimaging-core-docs.readthedocs.io/en/latest/pages/atlases.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://neuroimaging-core-docs.readthedocs.io/en/latest/pages/atlases.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>中国人脑MRI常模公开数据库</title>
      <link>https://chenfei-ye.github.io/zh/post/202302_hc_cohort/</link>
      <pubDate>Sun, 12 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202302_hc_cohort/</guid>
      <description>&lt;h2 id=&#34;chcp-中国人脑图谱&#34;&gt;CHCP-中国人脑图谱&lt;/h2&gt;
&lt;p&gt;北大高家红课题组公开，1.85 TB，365个人，西门子prisma扫描，包含基于中国人群的脑部MRI高分辨率结构影像（T1W 和 T2W）、静息态功能影像（rfMRI）、任务态功能影像（tfMRI）以及高角分辨率的扩散加权影像（dMRI），还包括相应的认知与行为数据。&lt;/p&gt;
&lt;p&gt;Ge, J., Yang, G., Han, M. &lt;em&gt;et al.&lt;/em&gt; Increasing diversity in connectomics with the Chinese Human Connectome Project. &lt;em&gt;Nat Neurosci&lt;/em&gt;  &lt;strong&gt;26&lt;/strong&gt;, 163–172 (2023). &lt;a href=&#34;https://doi.org/10.1038/s41593-022-01215-1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1038/s41593-022-01215-1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下载地址：https://www.chinese-hcp.cn/&lt;/p&gt;
&lt;h2 id=&#34;slim-西南大学纵向多模态大学生脑影像&#34;&gt;SLIM-西南大学纵向多模态大学生脑影像&lt;/h2&gt;
&lt;p&gt;数据介绍：&lt;a href=&#34;http://fcon_1000.projects.nitrc.org/indi/retro/southwestuni_qiu_index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://fcon_1000.projects.nitrc.org/indi/retro/southwestuni_qiu_index.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Liu W, Wei D, Chen Q, Yang W, Meng J, Wu G, Bi T, Zhang Q, Zuo XN, Qiu J. Longitudinal test-retest neuroimaging data from healthy young adults in southwest China. Sci Data. 2017 Feb 14;4:170017. doi: 10.1038/sdata.2017.17. PMID: 28195583; PMCID: PMC5308199.&lt;/p&gt;
&lt;p&gt;The data collection was initiated in November 2011 and was terminated in January 2015. using 3T Siemens Trio
包含3D-T1w/DTI/rs-fMRI&lt;/p&gt;
&lt;p&gt;下载方式：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 下载duck CLI工具，可在Linux环境安装 
echo -e &amp;#34;deb https://s3.amazonaws.com/repo.deb.cyberduck.io stable main&amp;#34; | sudo tee /etc/apt/sources.list.d/cyberduck.list &amp;gt; /dev/null 
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys FE7097963FEFBE72 
sudo apt-get update 
sudo apt-get install duck 

# 读取亚马逊云S3的目录 
duck --verbose -u anonymous --list s3:/fcp-indi/data/Projects/INDI/SLIM/RawDataTars/ 

# 下载tar数据到本地 
duck --verbose -u anonymous --download s3:/fcp-indi/data/Projects/INDI/SLIM/RawDataTars/ ./
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;sald-西南大学全生命周期横向队列脑影像&#34;&gt;SALD-西南大学全生命周期横向队列脑影像&lt;/h2&gt;
&lt;p&gt;数据介绍：&lt;a href=&#34;http://fcon_1000.projects.nitrc.org/indi/retro/southwestuni_qiu_index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://fcon_1000.projects.nitrc.org/indi/retro/sald.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wei D, Zhuang K, Ai L, Chen Q, Yang W, Liu W, Wang K, Sun J, Qiu J. Structural and functional brain scans from the cross-sectional Southwest University adult lifespan dataset. Sci Data. 2018 Jul 17;5:180134. doi: 10.1038/sdata.2018.134. PMID: 30015807; PMCID: PMC6049036.&lt;/p&gt;
&lt;p&gt;497 healthy adults (age range: 19-80 years; 308 Females, 187 Males) were recruited and completed 3D-T1w and rs-fmri (bids format) using 3T Siemens Trio&lt;/p&gt;
&lt;p&gt;下载方式：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 下载duck CLI工具，可在Linux环境安装 
echo -e &amp;#34;deb https://s3.amazonaws.com/repo.deb.cyberduck.io stable main&amp;#34; | sudo tee /etc/apt/sources.list.d/cyberduck.list &amp;gt; /dev/null 
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys FE7097963FEFBE72 
sudo apt-get update 
sudo apt-get install duck 

# 读取亚马逊云S3的目录 
duck --verbose -u anonymous --list s3:/fcp-indi/data/Projects/INDI/SALD/ 

# 下载tar数据到本地 
duck --verbose -u anonymous --download s3:/fcp-indi/data/Projects/INDI/SALD/ ./
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;北师大国重180例大学生多模态脑影像数据库&#34;&gt;北师大国重180例大学生多模态脑影像数据库&lt;/h2&gt;
&lt;p&gt;数据描述: &lt;a href=&#34;http://fcon_1000.projects.nitrc.org/indi/retro/BeijingEnhanced.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://fcon_1000.projects.nitrc.org/indi/retro/BeijingEnhanced.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;These data include 180 healthy controls from a community (student) sample at Beijing Normal University in China. Compared to the Beijing_Zang dataset in the 1000 Functional Connectomes Classic collection these data include IQ scores for a subset of participants (n=55) and a 64 directions DTI scan for all participants.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MRF-Net: A multi-branch residual fusion network for fast and accurate whole-brain MRI segmentation</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2022_j_mrfnet/</link>
      <pubDate>Fri, 16 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2022_j_mrfnet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ensemble learning  via supervision augmentation for white matter hyperintensity segmentation</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2022_j_wmh_ensemble/</link>
      <pubDate>Thu, 15 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2022_j_wmh_ensemble/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Brain age vector: A measure of brain aging with enhanced neurodegenerative disorder specificity</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2022_j_hbm_brainage/</link>
      <pubDate>Mon, 12 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2022_j_hbm_brainage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jupyter远程调试docker容器</title>
      <link>https://chenfei-ye.github.io/zh/post/202206_jupyter_docker/</link>
      <pubDate>Sat, 18 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202206_jupyter_docker/</guid>
      <description>&lt;h2 id=&#34;场景&#34;&gt;场景&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://chenfei-ye.github.io/zh/post/202206_vscode_docker/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;上一篇&lt;/a&gt;写了如何使用vscode远程连接服务器的docker容器进行debug，这篇简单记录一下如何使用jupyter远程连接服务器的docker容器。&lt;/p&gt;
&lt;p&gt;场景： 本地win10笔记本，远程连接远程ubuntu服务器的docker容器&lt;/p&gt;
&lt;p&gt;使用jupyter相对于vscode的优势：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;动态笔记脚本，Markdown与code的完美结合&lt;/li&gt;
&lt;li&gt;画图，模型训练&lt;/li&gt;
&lt;li&gt;快速运行下载的开源&lt;code&gt;ipynb&lt;/code&gt;文件&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当然对于神经影像pipeline项目，个人更偏爱vscode去debug&lt;/p&gt;
&lt;p&gt;言归正传：&lt;/p&gt;
&lt;h3 id=&#34;一服务器端容器设置&#34;&gt;&lt;strong&gt;一、服务器端容器设置&lt;/strong&gt;&lt;/h3&gt;
&lt;h4 id=&#34;1容器启动设置端口&#34;&gt;&lt;strong&gt;1、容器启动，设置端口&lt;/strong&gt;&lt;/h4&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 建议提前启动一个tmux窗口，防止远端服务断电断网
docker run -it --rm --gpus all -p 9999:9999 mindsgo-sz-docker.pkg.coding.net/neuroimage_analysis/base/msg_baseimage_cuda11:v1.1
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;2生成notebook-配置文件&#34;&gt;&lt;strong&gt;2、生成notebook 配置文件&lt;/strong&gt;&lt;/h4&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;apt-get install jupyter
apt-get install ipython
jupyter notebook --generate-config
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;3生成密码&#34;&gt;&lt;strong&gt;3、生成密码&lt;/strong&gt;&lt;/h4&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;jupyter notebook password
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;此时会在&lt;code&gt;/root/.jupyter/jupyter_notebook_config.json&lt;/code&gt;中生成密文。复制该密文，如&lt;code&gt;sha1:56a8dc892ab2:239cb1f1bda7f8614e546853e8298efc566489d9&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;4修改配置文件&#34;&gt;&lt;strong&gt;4、修改配置文件&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在&lt;code&gt;/root/.jupyter/jupyter_notebook_config.py&lt;/code&gt;中添加这几行&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;c.NotebookApp.ip=&amp;#39;*&amp;#39;
c.NotebookApp.password = u&amp;#39;刚才复制的那个密文&amp;#39;
c.NotebookApp.open_browser = False
c.NotebookApp.port =9999 
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;5安装python3-dev&#34;&gt;&lt;strong&gt;5、安装python3-dev&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;提前解决jupyter无法连接python3服务器内核 一直显示正在连接服务器的问题&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;apt-get install python3-dev
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;6安装ipykernel&#34;&gt;&lt;strong&gt;6、安装ipykernel&lt;/strong&gt;&lt;/h4&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 将当前python环境添加进jupyter kernel
pip install ipykernel
python -m ipykernel install --name cye（你的环境名）`
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;7启动jupyter&#34;&gt;&lt;strong&gt;7、启动jupyter&lt;/strong&gt;&lt;/h4&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;jupyter notebook --ip=0.0.0.0 --no-browser --allow-root --port 9999
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;二win10本地相关配置&#34;&gt;&lt;strong&gt;二、win10本地相关配置&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;假设windows环境已成功安装anaconda和jupyter&lt;/p&gt;
&lt;h4 id=&#34;1连接远程服务器&#34;&gt;&lt;strong&gt;1、连接远程服务器：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;打开&lt;code&gt;Anaconda prompt&lt;/code&gt;终端，连接远端：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ssh -L 9999:localhost:9999 [用户名]@[主机IP]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;此时需输入远端服务器密码（不是docker容器中刚才新设的密码）&lt;/p&gt;
&lt;h4 id=&#34;2浏览器打开jupyter&#34;&gt;&lt;strong&gt;2、浏览器打开jupyter：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;本地浏览器输入&lt;a href=&#34;http://localhost:9999/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://localhost:9999&lt;/a&gt;
然后输入登录Jupyter Notebook的密码（即docker容器中刚才新设的密码），选择刚才新建的kernel环境 (e.g., &lt;code&gt;cye&lt;/code&gt;)。&lt;/p&gt;
&lt;p&gt;BINGO！&lt;/p&gt;
&lt;h3 id=&#34;三参考资料&#34;&gt;&lt;strong&gt;三，参考资料&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_42001765/article/details/96144442&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://blog.csdn.net/qq_42001765/article/details/96144442&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/using-jupyter-notebook-running-on-a-remote-docker-container-via-ssh-ea2c3ebb9055&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://towardsdatascience.com/using-jupyter-notebook-running-on-a-remote-docker-container-via-ssh-ea2c3ebb9055&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/u012325865/article/details/99692108&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://blog.csdn.net/u012325865/article/details/99692108&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>python进程传参踩坑：为何单变量参数被识别为多变量</title>
      <link>https://chenfei-ye.github.io/zh/post/202206_python_tuple/</link>
      <pubDate>Wed, 15 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202206_python_tuple/</guid>
      <description>&lt;h3 id=&#34;背景&#34;&gt;背景：&lt;/h3&gt;
&lt;p&gt;新建一个脚本进程，需要如下传参：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;fastcsr_input = [&amp;#39;--t1&amp;#39;,input_nu_image, &amp;#39;--L4&amp;#39;, t1_label_L4]
p_fastcsr = multiprocessing.Process(target=FastCSR_pipeline.main, args=(fastcsr_input))
p_fastcsr.start()
p_fastcsr.join()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;脚本&lt;code&gt;FastCSR_pipeline.main&lt;/code&gt;函数只接受一个输入变量，但运行时报错：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;python TypeError: write() takes exactly 1 argument (but 4 were given)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;方案&#34;&gt;方案：&lt;/h3&gt;
&lt;p&gt;折腾半天找到&lt;a href=&#34;https://stackoverflow.com/questions/1559125/string-arguments-in-python-multiprocessing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原因&lt;/a&gt;，&lt;code&gt;multiprocessing.Process&lt;/code&gt;中&lt;code&gt;args&lt;/code&gt;变量是&lt;code&gt;tuple&lt;/code&gt;类型，&lt;code&gt;tuple&lt;/code&gt;中若只有一个对象，需要在后面加一个逗号。。&lt;/p&gt;
&lt;p&gt;所以修改代码为：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;fastcsr_input = [&amp;#39;--t1&amp;#39;,input_nu_image, &amp;#39;--L4&amp;#39;, t1_label_L4]
p_fastcsr = multiprocessing.Process(target=FastCSR_pipeline.main, args=(fastcsr_input,))
p_fastcsr.start()
p_fastcsr.join()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;即可顺利运行&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>FSL-Dokerfile编写</title>
      <link>https://chenfei-ye.github.io/zh/post/202206_dockerfile_fsl/</link>
      <pubDate>Sun, 12 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202206_dockerfile_fsl/</guid>
      <description>&lt;p&gt;通过下载源文件安装FSL（测试成功，但不稳定，取决于网络）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Docker&#34; data-lang=&#34;Docker&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;RUN&lt;/span&gt; apt update &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get install -y &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;    libegl1-mesa-dev &lt;span class=&#34;se&#34;&gt;\ &lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;    libopenblas-dev&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# fsl install  &lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ENV&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;FSLDIR&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/opt/fsl-6.0.3&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nv&#34;&gt;FSLOUTPUTTYPE&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;NIFTI_GZ &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nv&#34;&gt;PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/opt/fsl-6.0.3/bin:&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$PATH&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;RUN&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Downloading FSL ...&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; mkdir -p /opt/fsl-6.0.3 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; curl -fsSL --retry &lt;span class=&#34;m&#34;&gt;20&lt;/span&gt; https://fsl.fmrib.ox.ac.uk/fsldownloads/fsl-6.0.3-centos6_64.tar.gz &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; tar -xz -C /opt/fsl-6.0.3 --strip-components &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      --exclude&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fsl/doc&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      --exclude&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fsl/data/atlases&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      --exclude&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fsl/data/possum&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      --exclude&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fsl/src&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      --exclude&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fsl/extras/src&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      --exclude&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fsl/bin/fslview*&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      --exclude&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fsl/bin/FSLeyes&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Installing FSL conda environment ...&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; sed -i -e &lt;span class=&#34;s2&#34;&gt;&amp;#34;/fsleyes/d&amp;#34;&lt;/span&gt; -e &lt;span class=&#34;s2&#34;&gt;&amp;#34;/wxpython/d&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;         &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;FSLDIR&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;/etc/fslconf/fslpython_environment.yml &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; bash /opt/fsl-6.0.3/etc/fslconf/fslpython_install.sh -f /opt/fsl-6.0.3 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; find &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;FSLDIR&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;/fslpython/envs/fslpython/lib/python3.7/site-packages/ -type d -name &lt;span class=&#34;s2&#34;&gt;&amp;#34;tests&amp;#34;&lt;/span&gt;  -print0 &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; xargs -0 rm -r &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;FSLDIR&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;/fslpython/bin/conda clean --all&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过本地文件安装FSL（不执行&lt;code&gt;fslpython_install.sh&lt;/code&gt; 不会影响常用命令，但会影响bianca, FSLeyes等）。 &lt;strong&gt;注意&lt;/strong&gt;：最后一行用于指定eddy_cuda&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Docker&#34; data-lang=&#34;Docker&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;RUN&lt;/span&gt; apt update &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get install -y &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;    libegl1-mesa-dev &lt;span class=&#34;se&#34;&gt;\ &lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;    libopenblas-dev&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;COPY&lt;/span&gt; fsl-6.0.4-centos6_64.tar.gz /opt/&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;RUN&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Downloading FSL ...&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; mkdir -p /opt/fsl-6.0.4 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; tar -xzvf /opt/fsl-6.0.4-centos6_64.tar.gz -C /opt/fsl-6.0.4 --strip-components &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      --exclude&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fsl/doc&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      --exclude&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fsl/data/atlases&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      --exclude&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fsl/data/possum&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      --exclude&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fsl/src&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      --exclude&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fsl/extras/src&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      --exclude&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fsl/bin/fslview*&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      --exclude&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fsl/bin/FSLeyes&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; rm /opt/fsl-6.0.4-centos6_64.tar.gz &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; ln -s /opt/fsl-6.0.4/bin/eddy_cuda9.1 /opt/fsl-6.0.4/bin/eddy_cuda &lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;推荐&lt;/strong&gt;： 简化安装FSL-6.0.4&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Docker&#34; data-lang=&#34;Docker&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;# Download minified FSL (6.0.4)&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WORKDIR&lt;/span&gt;&lt;span class=&#34;s&#34;&gt; /opt/fsl&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;RUN&lt;/span&gt; curl -fsSL https://osf.io/dv258/download &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; tar xz --strip-components &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ENV&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;FSLDIR&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/opt/fsl&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;nv&#34;&gt;FSLOUTPUTTYPE&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;NIFTI_GZ &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;nv&#34;&gt;FSLMULTIFILEQUIT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;TRUE&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;nv&#34;&gt;FSLTCLSH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/opt/fsl/bin/fsltclsh&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;nv&#34;&gt;FSLWISH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/opt/fsl/bin/fslwish&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;nv&#34;&gt;PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$PATH&lt;/span&gt;:/opt/fsl/bin &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;nv&#34;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$LD_LIBRARY_PATH&lt;/span&gt;:&lt;span class=&#34;nv&#34;&gt;$FSLDIR&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>VScode远程调试docker容器</title>
      <link>https://chenfei-ye.github.io/zh/post/202206_vscode_docker/</link>
      <pubDate>Sun, 12 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202206_vscode_docker/</guid>
      <description>&lt;h2 id=&#34;场景&#34;&gt;场景&lt;/h2&gt;
&lt;p&gt;一般深度学习算法的训练和调试环境都在服务器端，想不做配置就直接使用vscode进行debug不太可能。而使用远程服务器时，一般用docker进行环境部署的情况比较多。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用vscode远程连接服务器debug&lt;/strong&gt;和&lt;strong&gt;远程服务器上的docker&lt;/strong&gt;容器&lt;strong&gt;进行debug&lt;/strong&gt;，两者关键区别在于后者在docker容器创建时需要注意端口映射问题。本文主要讲解&lt;strong&gt;vscode远程连接服务器上的docker环境进行debug&lt;/strong&gt;的具体步骤。&lt;/p&gt;
&lt;h3 id=&#34;一服务器端的docker容器创建时需要注意的问题&#34;&gt;&lt;strong&gt;一、服务器端的docker容器创建时需要注意的问题&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;创建容器时，一般按照如下命令创建。其中，端口映射参数：&lt;strong&gt;-p&lt;/strong&gt; &lt;strong&gt;宿主机port:容器port&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;sudo docker run &amp;ndash;gpus all -it -d -p 8010:22 &amp;ndash;name 容器名称 -v 本地路径或服务器物理路径：容器内路径 -d 镜像id /bin/bash&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上面的命令中**-p 8010:22**，就是将容器的22号端口（ssh服务端口）映射到宿主机（服务器）的8010端口。在本文中，因为需要使用ssh服务端口，所以，容器端口必须写22。（宿主机端口可以写成其他值，但是也不能乱写，防止端口冲突）。这样，在后续的vscode配置中，需要将连接端口写成宿主机（服务器端口），例如本文中的8010端口。下文中会介绍如何配置连接端口。&lt;/p&gt;
&lt;p&gt;注意：在整个配置过程中，应该保持创建的docker容器处于运行状态，方便后续调试。&lt;/p&gt;
&lt;h3 id=&#34;二docker容器内部相关配置&#34;&gt;&lt;strong&gt;二、docker容器内部相关配置&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;本文介绍的方法需要使用ssh服务进行通信，因此，需要在环境中安装ssh。&lt;/p&gt;
&lt;h4 id=&#34;1进入容器中使用如下命令修改root用户密码&#34;&gt;&lt;strong&gt;1、进入容器中，使用如下命令修改root用户密码：&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;passwd&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;2检查容器内部是否安装-openssh-server与openssh-client若没安装执行如下命令&#34;&gt;&lt;strong&gt;2、检查容器内部是否安装 openssh-server与openssh-client，若没安装，执行如下命令：&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;apt update
apt-get install openssh-server
apt-get install openssh-client
apt-get install vim&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;若&lt;code&gt;apt update&lt;/code&gt;更新失败，可以换以下清华源，替换文件&lt;code&gt;/etc/apt/sources.list&lt;/code&gt;：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;3修改ssh配置文件以下选项&#34;&gt;&lt;strong&gt;3、修改ssh配置文件以下选项:&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;vim /etc/ssh/sshd_config&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在末尾增加如下内容(直接复制即可)：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;PermitRootLogin yes #允许root用户使用ssh登录&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;4启动sshd服务&#34;&gt;&lt;strong&gt;4、启动sshd服务&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;/etc/init.d/ssh restart&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;三在vscode上的相关配置&#34;&gt;&lt;strong&gt;三、在vscode上的相关配置&lt;/strong&gt;&lt;/h3&gt;
&lt;h4 id=&#34;1安装remote-ssh插件&#34;&gt;&lt;strong&gt;1、安装remote-ssh插件&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;在vscode最左侧应用“&lt;strong&gt;扩展&lt;/strong&gt;”中搜索&lt;strong&gt;remote-ssh&lt;/strong&gt;插件，然后安装。安装完成之后，会在“&lt;strong&gt;扩展&lt;/strong&gt;”图标下方出现“&lt;strong&gt;远程资源管理器&lt;/strong&gt;”图标。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;2配置vscode的config文件&#34;&gt;&lt;strong&gt;2、配置vscode的config文件&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;单击“&lt;strong&gt;远程资源管理器&lt;/strong&gt;”图标，然后单击“&lt;strong&gt;配置&lt;/strong&gt;”按钮进行配置，此时vscode会显示“Select SSH configuration file to update”，选择路径中带有“.ssh”的config文件。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;填写config文件内容，注意按照如下格式填写：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Host&lt;/strong&gt;可以根据自己的喜好起一个标志名称。&lt;strong&gt;HostName&lt;/strong&gt;必须填写需要远程连接的服务器IP地址。&lt;strong&gt;User&lt;/strong&gt;此处因为远程的是服务器上配置的docker容器，默认用户名是&lt;strong&gt;root&lt;/strong&gt;，此处需要改下为root。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;特别注意&lt;/strong&gt;：由于需要远程连接的是服务器上的docker容器，而且前面提到：ssh服务器的22号端口已经映射为8010,因此，务必增加一个&lt;strong&gt;Port&lt;/strong&gt;，填写自己映射的端口。如果只是远程服务器，不需要用docker容器，则，不需要增加Port这一行。配置完成后，保存配置。&lt;/p&gt;
&lt;h4 id=&#34;3开启远程连接&#34;&gt;&lt;strong&gt;3、开启远程连接&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;如下图所示，config文件中写的Host名称alias就会显示在最左侧。此时，单击“新建连接”按钮，vscode会重新打开一个窗口，提示输入远程服务器的密码，注意，此时必须填入docker容器中创建的用户密码。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;回车之后，可能会提示选择远程服务器的平台是哪一种系统类型，选项有linux\windows\MAC。应该选择vscode安装的系统平台类型。 选择完成之后，回车即可。此时，在vscode的“终端”窗口可以看到进入docker容器的命令行格式。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;在“终端”窗口可以查看以下远程连接的环境是否正确。 打开远程服务器上的代码，可以在代码任意行最左侧打断点，按F5快捷键可以debug运行。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;四转载来源&#34;&gt;&lt;strong&gt;四，转载来源&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.tencent.com/developer/article/1851508&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://cloud.tencent.com/developer/article/1851508&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/hanchaobiao/article/details/84069299&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://blog.csdn.net/hanchaobiao/article/details/84069299&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>用于神经影像算法开发的基础镜像</title>
      <link>https://chenfei-ye.github.io/zh/post/202206_dockerfile_all/</link>
      <pubDate>Sun, 12 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202206_dockerfile_all/</guid>
      <description>&lt;h2 id=&#34;使用&#34;&gt;使用&lt;/h2&gt;
&lt;p&gt;把以下命令添加到&lt;code&gt;Dockfile&lt;/code&gt;即可：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;FROM mindsgo-sz-docker.pkg.coding.net/neuroimage_analysis/base/msg_baseimage_cuda11:v1.1
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;说明&#34;&gt;说明&lt;/h2&gt;
&lt;p&gt;工具包括：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ubuntu + cuda11 + python== 3.8.3 + torch== 1.7.0 + ants== 2.3.1 mrtrix3== 3.0.3 fsl== 6.0.4 c3d== nightly&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;python包：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;astor                  0.8.1           &lt;br&gt;
backcall               0.2.0           &lt;br&gt;
beautifulsoup4         4.9.3           &lt;br&gt;
bids-validator         1.9.3           &lt;br&gt;
certifi                2020.6.20       &lt;br&gt;
cffi                   1.14.0          &lt;br&gt;
chardet                3.0.4           &lt;br&gt;
ci-info                0.2.0           &lt;br&gt;
click                  8.1.3           &lt;br&gt;
conda                  4.9.1           &lt;br&gt;
conda-build            3.20.5          &lt;br&gt;
conda-package-handling 1.7.0           &lt;br&gt;
cryptography           2.9.2           &lt;br&gt;
cycler                 0.11.0          &lt;br&gt;
dataclasses            0.6             &lt;br&gt;
decorator              4.4.2           &lt;br&gt;
dnspython              2.0.0           &lt;br&gt;
docopt                 0.6.2           &lt;br&gt;
etelemetry             0.3.0           &lt;br&gt;
filelock               3.0.12          &lt;br&gt;
fonttools              4.33.3          &lt;br&gt;
formulaic              0.3.4           &lt;br&gt;
future                 0.18.2          &lt;br&gt;
glob2                  0.7             &lt;br&gt;
idna                   2.9             &lt;br&gt;
interface-meta         1.3.0           &lt;br&gt;
ipython                7.18.1          &lt;br&gt;
ipython-genutils       0.2.0           &lt;br&gt;
isodate                0.6.1           &lt;br&gt;
jedi                   0.17.2          &lt;br&gt;
Jinja2                 2.11.2          &lt;br&gt;
joblib                 1.1.0           &lt;br&gt;
kiwisolver             1.4.2           &lt;br&gt;
libarchive-c           2.9             &lt;br&gt;
looseversion           1.0.1           &lt;br&gt;
lxml                   4.8.0           &lt;br&gt;
MarkupSafe             1.1.1           &lt;br&gt;
matplotlib             3.5.2           &lt;br&gt;
mkl-fft                1.2.0           &lt;br&gt;
mkl-random             1.1.1           &lt;br&gt;
mkl-service            2.3.0           &lt;br&gt;
networkx               2.8             &lt;br&gt;
&lt;strong&gt;nibabel&lt;/strong&gt;                3.2.2           &lt;br&gt;
&lt;strong&gt;nilearn&lt;/strong&gt;                0.9.1           &lt;br&gt;
&lt;strong&gt;nipype&lt;/strong&gt;                 1.8.1           &lt;br&gt;
num2words              0.5.10          &lt;br&gt;
numpy                  1.19.2          &lt;br&gt;
olefile                0.46            &lt;br&gt;
packaging              21.3            &lt;br&gt;
pandas                 1.4.2           &lt;br&gt;
parso                  0.7.0           &lt;br&gt;
pexpect                4.8.0           &lt;br&gt;
pickleshare            0.7.5           &lt;br&gt;
Pillow                 9.0.0           &lt;br&gt;
pip                    20.0.2          &lt;br&gt;
pkginfo                1.6.0           &lt;br&gt;
prompt-toolkit         3.0.8           &lt;br&gt;
prov                   2.0.0           &lt;br&gt;
psutil                 5.7.2           &lt;br&gt;
ptyprocess             0.6.0           &lt;br&gt;
&lt;strong&gt;pybids&lt;/strong&gt;                 0.15.1          &lt;br&gt;
pycosat                0.6.3           &lt;br&gt;
pycparser              2.20            &lt;br&gt;
pydot                  1.4.2           &lt;br&gt;
Pygments               2.7.1           &lt;br&gt;
pyOpenSSL              19.1.0          &lt;br&gt;
pyparsing              3.0.9           &lt;br&gt;
PySocks                1.7.1           &lt;br&gt;
python-dateutil        2.8.2           &lt;br&gt;
python-etcd            0.4.5           &lt;br&gt;
pytz                   2020.1          &lt;br&gt;
PyYAML                 5.3.1           &lt;br&gt;
rdflib                 6.1.1           &lt;br&gt;
requests               2.23.0          &lt;br&gt;
ruamel-yaml            0.15.87         &lt;br&gt;
&lt;strong&gt;scikit-learn&lt;/strong&gt;           1.1.0           &lt;br&gt;
scipy                  1.8.0           &lt;br&gt;
setuptools             46.4.0.post20200518
simplejson             3.17.6          &lt;br&gt;
six                    1.14.0          &lt;br&gt;
soupsieve              2.0.1           &lt;br&gt;
SQLAlchemy             1.3.24          &lt;br&gt;
threadpoolctl          3.1.0           &lt;br&gt;
&lt;strong&gt;torch&lt;/strong&gt;                  1.7.0           &lt;br&gt;
torchelastic           0.2.1           &lt;br&gt;
torchvision            0.8.0           &lt;br&gt;
tqdm                   4.46.0          &lt;br&gt;
traitlets              5.0.5           &lt;br&gt;
traits                 6.3.2           &lt;br&gt;
typing-extensions      3.7.4.3         &lt;br&gt;
urllib3                1.25.8          &lt;br&gt;
wcwidth                0.2.5           &lt;br&gt;
wheel                  0.34.2          &lt;br&gt;
wrapt                  1.14.1&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;彩蛋&#34;&gt;彩蛋&lt;/h2&gt;
&lt;p&gt;该镜像已内置ssh-server服务，可直接利用vscode实现远程镜像开发和调试&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;启动容器，指定端口（如8088）&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;docker run --gpus all -it --rm -p 8088:22 mindsgo-sz-docker.pkg.coding.net/neuroimage_analysis/base/msg_baseimage_cuda11:v1.1
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;在容器console中启动ssh服务：&lt;code&gt;/etc/init.d/ssh restart&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;在VScode中的remote config文件新增Host， 添加对应IP、用户名、端口即可（&lt;a href=&#34;https://chenfei-ye.github.io/post/202206_dockerfile_all/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;点此参考具体细节&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;容器的管理员密码：&lt;code&gt;mindsgo123&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>CUDA版本、显卡算力、Pytorch对应关系</title>
      <link>https://chenfei-ye.github.io/zh/post/202206_cuda_pytorch/</link>
      <pubDate>Sat, 11 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202206_cuda_pytorch/</guid>
      <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;试用合作医院提供的堡垒机服务器，自带的NVIDIA-A6000显卡不支持结构像自动分割的pipeline镜像，运行时报错capability sm_86 is not compatible。发现是由于显卡的架构比较新，旧版pytorch库不支持。同时根据输出可以看到 The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70 sm_75当前pytorch只能支持上面几种（显卡算力）架构。&lt;/p&gt;
&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;
&lt;p&gt;把基础镜像直接更新到&lt;code&gt;pytorch/pytorch:1.7.0-cuda11.0-cudnn8-runtime&lt;/code&gt;，解决。
NOTE: CUDA10.x最高支持算力7.x; CUDA11.0最高支持算力8.x&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://imgpp.com/s1/2022/06/12/cuda_version.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://imgpp.com/s1/2022/06/12/torch_version.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>神经纤维格式转换：tck转trk</title>
      <link>https://chenfei-ye.github.io/zh/post/202206_tck2trk/</link>
      <pubDate>Sat, 11 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202206_tck2trk/</guid>
      <description>&lt;h2 id=&#34;场景&#34;&gt;场景&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;MRtrix3&lt;/code&gt;输出的tck神经纤维文件，需要转换成&lt;code&gt;TrackVis&lt;/code&gt;能识别的trk格式&lt;/p&gt;
&lt;h2 id=&#34;python实现&#34;&gt;Python实现&lt;/h2&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#!/usr/bin/env python

import json
import nibabel as nib
from nibabel.streamlines import Field
from nibabel.orientations import aff2axcodes


def main():

    tck_file = &amp;#39;/home/amax/data/cye/TractSeg_testcase/KAIPU-mating/dwi_recon_output/fiber_tracts/Fibers/CC.tck&amp;#39;
    anatomy_file = &amp;#39;/home/amax/data/cye/TractSeg_testcase/KAIPU-mating/dwi_recon_output/fiber_tracts/bundle_segmentations/CC.nii.gz&amp;#39;
    trk_file = &amp;#39;/home/amax/data/cye/TractSeg_testcase/KAIPU-mating/dwi_recon_output/fiber_tracts/Fibers/CC.trk&amp;#39;

    nii = nib.load(anatomy_file)

    header = {}
    header[Field.VOXEL_TO_RASMM] = nii.affine.copy()
    header[Field.VOXEL_SIZES] = nii.header.get_zooms()[:3]
    header[Field.DIMENSIONS] = nii.shape[:3]
    header[Field.VOXEL_ORDER] = &amp;#34;&amp;#34;.join(aff2axcodes(nii.affine))

    tck = nib.streamlines.load(tck_file)
    nib.streamlines.save(tck.tractogram, trk_file, header=header)

        
if __name__ == &amp;#39;__main__&amp;#39;:
    main()
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>R常见统计模型使用</title>
      <link>https://chenfei-ye.github.io/zh/post/202205_r_statistics/</link>
      <pubDate>Tue, 31 May 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/post/202205_r_statistics/</guid>
      <description>&lt;p&gt;数据描述：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;summary(A) psych::describe(A)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;直方图：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;hist(A)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;概率密度图density plot:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;hist(A,prob=TRUE) lines(density(A, bw=&amp;quot;SJ&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;累计分布图CDF：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;plot(ecdf(A), do.points=FALSE, verticals=TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;拟合同参数高斯分布的CDF：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lines(x, pnorm(x, mean=mean(A), sd=sqrt(var(A))), lty=3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;双样本检验&lt;/p&gt;
&lt;p&gt;经典的two-sample t-test：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;t.test(A, B, var.equal=TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果不满足同方差，则用 Welch modified two-sample t-test :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;res=t.test(A, B) res$p.val
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;检验同方差的方法可用F-test:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var.test(A, B)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果不满足正态性，则用非参数检验，即two-sample Mann-Whitney test:（但是仍然assume两个分布是相似的）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wilcox.test(A, B)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果连分布也很不相似，则考虑用permutation test&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;coin::independence_test(Length ~ Hand, data = Data)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;是否满足正态分布，有三种方法检验：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;QQ图：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    par(pty=&amp;#34;s&amp;#34;) # arrange for a square figure region qqnorm(long) qqline(long)
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Shapiro-Wilk test：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    shapiro.test(A) # Shapiro-Wilk normality test
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Kolmogorov-Smirnov test：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    ks.test(A, &amp;#34;pnorm&amp;#34;, mean = mean(A), sd = sqrt(var(A)))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;独立性检验：&lt;/p&gt;
&lt;p&gt;卡方分布有一个重要应用就是根据样本数据来检验两个分类变量的独立性，我们以CO2数据为例来说明chisq.test函数的使用，help(CO2)可以了解更多信息。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;data(CO2) #读入内置的数据包，其中Type和Treatmen是其中两个分类变量。 
chisq.test(table(CO2$Type,CO2$Treatment)) #检验这两个因子之间是否独立
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结果显示P值为0.82，因此可以认为两因子之间独立。在样本较小的情况下，还可以使用fisher精确检验，对应的函数是&lt;code&gt;fisher.test&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;proportion test&lt;/code&gt;:(在两个group的情况下，结果和卡方检验是一样的)&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;library(MASS) 
table(quine$Eth, quine$Sex) 
prop.test(table(quine$Eth, quine$Sex), correct=FALSE)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;ANOVA：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;anova(lm(y~x)) 
summary(aov(y~x)) # summary(aov(lm(y~x)))也是一样的结果 
summary(aov(y~x+covariate)) # ANCOVA 
summary(test)[[1]][[&amp;#34;Pr(&amp;gt;F)&amp;#34;]]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Post-hoc:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;TukeyHSD(aov(y ~ x, data))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;对于ANCOVA的post hoc:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;TukeyHSD(aov(y ~ x+covariate, data),which=&amp;#39;x&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果ANOVA不满足正态性，用Kruskal-Wallis非参数检验：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kruskal.test(y~x, data = df) # post-hoc for Kruskal-Wallis Test： Steel-Dwass test library(FSA) dunnTest(y~x, data=df, method=&amp;#34;bonferroni&amp;#34;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;多重比较校正：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ps &amp;lt;- runif(20, max=.2) 
def &amp;lt;- p.adjust(ps) 
bon &amp;lt;- p.adjust(ps, method=&amp;#34;bonferroni&amp;#34;) 
bh &amp;lt;- p.adjust(ps, method=&amp;#34;BH&amp;#34;) #Benjamini, Hochberg (1995) default fdr 
by &amp;lt;- p.adjust(ps, method=&amp;#34;BY&amp;#34;) #Benjamini, Yekutieli (2001) another fdr 
x = matrix(rnorm(10000*5),nrow=10000) 
y = matrix(rnorm(10000*5),nrow=10000) 
p = sapply(1:10000, function(i) t.test(x[i,],y[i,])$p.val) 
q = p.adjust(p, method = &amp;#34;fdr&amp;#34;)
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Regularizing Brain Age Prediction via Gated Knowledge Distillation</title>
      <link>https://chenfei-ye.github.io/zh/publication/c_2022_c_midl_brainage/</link>
      <pubDate>Wed, 23 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/c_2022_c_midl_brainage/</guid>
      <description>&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;[https://github.com/podismine/BrainAgeReg]%28https://github.com/podismine/BrainAgeReg%29&#34;&gt;code&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Three‑Dimensional Digital Reconstruction of the Cerebellar Cortex: Lobule Thickness, Surface Area Measurements, and Layer Architecture</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2022_j_cerebellar/</link>
      <pubDate>Mon, 14 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2022_j_cerebellar/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Coupling of brain activity and structural network in multiple sclerosis: A graph frequency analysis study</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2022_j_coupling_ms/</link>
      <pubDate>Thu, 27 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2022_j_coupling_ms/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Alteration of brain structural connectivity in progression of Parkinsons disease: A connectome-wide network analysis</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2021_j_pd_mdmr_neuclin/</link>
      <pubDate>Sun, 06 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2021_j_pd_mdmr_neuclin/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An anatomical knowledge-based MRI deep learning pipeline for white matter hyperintensity quantification associated with cognitive impairment</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2021_j_cmig/</link>
      <pubDate>Tue, 06 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2021_j_cmig/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multimodal MRI assessment for first episode psychosis- A major change in the thalamus and an efficient stratification of a subgroup</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2020_j_hbm/</link>
      <pubDate>Sat, 27 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2020_j_hbm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Epidemiology and transmission of COVID-19 in 391 cases and 1286 of their close contacts in Shenzhen, China: a retrospective cohort study</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2020_j_lancetid/</link>
      <pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2020_j_lancetid/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quantitative evaluation of iron content in idiopathic rapid eye movement sleep behavior disorder</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2019_j_movement_disorder/</link>
      <pubDate>Fri, 27 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2019_j_movement_disorder/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Extended multimodal whole-brain anatomical covariance analysis: detection of disrupted correlation networks related to amyloid deposition</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2019_j_eaca_heliyon/</link>
      <pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2019_j_eaca_heliyon/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Relationship between neuropsychological behavior and brain white matter in first-episode psychosis</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2019_j_schizores/</link>
      <pubDate>Thu, 27 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2019_j_schizores/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Connectome wide network analysis of white matter connectivity in Alzheimers disease</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2019_j_mdmr_neuclin/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2019_j_mdmr_neuclin/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://chenfei-ye.github.io/zh/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Eating...&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
  One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  Three
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Only the speaker can read these notes
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Press &lt;span class=&#34;sb&#34;&gt;`S`&lt;/span&gt; key to view
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {{% /speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/media/boards.jpg&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;#0000FF&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;my-style&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-css&#34; data-lang=&#34;css&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h3&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;navy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Atlas pre-selection strategies to enhance the efficiency and accuracy of multi-atlas brain segmentation tools</title>
      <link>https://chenfei-ye.github.io/zh/publication/j_2018_j_plos-one/</link>
      <pubDate>Fri, 27 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/publication/j_2018_j_plos-one/</guid>
      <description>&lt;p&gt;Please see the website for brain automatic parcellation &lt;a href=&#34;http://brainlabel.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pipeline &lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Project</title>
      <link>https://chenfei-ye.github.io/zh/project/example/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/project/example/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://chenfei-ye.github.io/zh/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/zh/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
