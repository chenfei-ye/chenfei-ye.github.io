<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pipeline | Chenfei Ye</title>
    <link>https://chenfei-ye.github.io/tag/pipeline/</link>
      <atom:link href="https://chenfei-ye.github.io/tag/pipeline/index.xml" rel="self" type="application/rss+xml" />
    <description>pipeline</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 15 Jun 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://chenfei-ye.github.io/media/icon_hu80a2544e7b046e76dea23103488b26f7_18404_512x512_fill_lanczos_center_3.png</url>
      <title>pipeline</title>
      <link>https://chenfei-ye.github.io/tag/pipeline/</link>
    </image>
    
    <item>
      <title>python进程传参踩坑：为何单变量参数被识别为多变量</title>
      <link>https://chenfei-ye.github.io/post/202206_python_tuple/</link>
      <pubDate>Wed, 15 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/post/202206_python_tuple/</guid>
      <description>&lt;h3 id=&#34;背景&#34;&gt;背景：&lt;/h3&gt;
&lt;p&gt;新建一个脚本进程，需要如下传参：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;fastcsr_input = [&amp;#39;--t1&amp;#39;,input_nu_image, &amp;#39;--L4&amp;#39;, t1_label_L4]
p_fastcsr = multiprocessing.Process(target=FastCSR_pipeline.main, args=(fastcsr_input))
p_fastcsr.start()
p_fastcsr.join()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;脚本&lt;code&gt;FastCSR_pipeline.main&lt;/code&gt;函数只接受一个输入变量，但运行时报错：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;python TypeError: write() takes exactly 1 argument (but 4 were given)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;方案&#34;&gt;方案：&lt;/h3&gt;
&lt;p&gt;折腾半天找到&lt;a href=&#34;https://stackoverflow.com/questions/1559125/string-arguments-in-python-multiprocessing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原因&lt;/a&gt;，&lt;code&gt;multiprocessing.Process&lt;/code&gt;中&lt;code&gt;args&lt;/code&gt;变量是&lt;code&gt;tuple&lt;/code&gt;类型，&lt;code&gt;tuple&lt;/code&gt;中若只有一个对象，需要在后面加一个逗号。。&lt;/p&gt;
&lt;p&gt;所以修改代码为：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;fastcsr_input = [&amp;#39;--t1&amp;#39;,input_nu_image, &amp;#39;--L4&amp;#39;, t1_label_L4]
p_fastcsr = multiprocessing.Process(target=FastCSR_pipeline.main, args=(fastcsr_input,))
p_fastcsr.start()
p_fastcsr.join()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;即可顺利运行&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CUDA版本、显卡算力、Pytorch对应关系</title>
      <link>https://chenfei-ye.github.io/post/202206_cuda_pytorch/</link>
      <pubDate>Sat, 11 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://chenfei-ye.github.io/post/202206_cuda_pytorch/</guid>
      <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;试用合作医院提供的堡垒机服务器，自带的NVIDIA-A6000显卡不支持结构像自动分割的pipeline镜像，运行时报错capability sm_86 is not compatible。发现是由于显卡的架构比较新，旧版pytorch库不支持。同时根据输出可以看到 The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70 sm_75当前pytorch只能支持上面几种（显卡算力）架构。&lt;/p&gt;
&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;
&lt;p&gt;把基础镜像直接更新到&lt;code&gt;pytorch/pytorch:1.7.0-cuda11.0-cudnn8-runtime&lt;/code&gt;，解决。
NOTE: CUDA10.x最高支持算力7.x; CUDA11.0最高支持算力8.x&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://imgpp.com/s1/2022/06/12/cuda_version.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://imgpp.com/s1/2022/06/12/torch_version.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
